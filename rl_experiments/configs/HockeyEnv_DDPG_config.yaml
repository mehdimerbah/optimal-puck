environment:
  name: "HockeyEnv"
  max_episode_steps: 250
  
training:
  max_episodes: 30000        
  max_timesteps: 250        
  seed: 42                  
  log_interval: 20          
  save_interval: 1000        
  render: false             
  train_iter: 32    
   

model:
  name: "DDPG"
    # DDPG-specific hyperparameters
  wandb_sweep_config:
    name: "HockeyEnv_DDPG"
    method: "grid"
    metric:
      name: "average_wins"
      goal: "maximize"
    parameters:
      batch_size:
        values: [128]
      learning_rate_actor:
        values: [1e-4]
      learning_rate_critic:
        values: [1e-4]
      discount:
        values: [0.95]
      noise_scale:
        values: [0.1]
      beta:
        values: [0.4]
      prioritized:
        values: [True]

evaluation:
  n_episodes: 100
  max_steps_per_episode: 250
  metrics:
    - "mean_return"
    - "episode_length"
