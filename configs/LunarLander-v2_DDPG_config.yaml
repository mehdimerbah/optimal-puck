environment:
  name: "LunarLanderContinuous-v2"
  continuous: true
  max_steps: 2000

models:
  ddpg:
    type: "ddpg"
    hidden_sizes_actor: [256, 256]
    hidden_sizes_critic: [256, 256]
    learning_rate_actor: 0.0001
    learning_rate_critic: 0.001
    buffer_size: 500000
    batch_size: 64
    discount: 0.99
    tau: 0.005  # Soft update rate for target networks
    noise_stddev: 0.1  # Standard deviation for exploration noise
    update_target_every: 1
    use_target_net: true
    training:
      max_episodes: 1500
      train_iter: 50  # Updates per episode
      log_interval: 25
      save_interval: 100
      eval_interval: 50
      random_seed: 123

training:
  max_episodes: 1500
  train_iter: 50
  log_interval: 25
  save_interval: 100
  eval_interval: 50

evaluation:
  n_episodes: 15
  max_steps_per_episode: 2000
  render: false
  metrics:
    - "episode_reward"
    - "episode_length"
